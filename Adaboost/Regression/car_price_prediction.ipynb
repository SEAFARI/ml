{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Used Car Price Prediction\n",
    "\n",
    "## 1) Problem statement.\n",
    "\n",
    "* This dataset comprises used cars sold on cardehko.com in India as well as important features of these cars.\n",
    "* If user can predict the price of the car based on input features.\n",
    "* Prediction results can be used to give new seller the price suggestion based on market condition.\n",
    "\n",
    "## 2) Data Collection.\n",
    "* The Dataset is collected from scrapping from cardheko webiste\n",
    "* The data consists of 13 column and 15411 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"./cardekho_imputated.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA CLEANING\n",
    "\n",
    "* Handling Missing values \n",
    "* Handling Duplicates\n",
    "* Check data type\n",
    "* Understand the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "car_name             0\n",
       "brand                0\n",
       "model                0\n",
       "vehicle_age          0\n",
       "km_driven            0\n",
       "seller_type          0\n",
       "fuel_type            0\n",
       "transmission_type    0\n",
       "mileage              0\n",
       "engine               0\n",
       "max_power            0\n",
       "seats                0\n",
       "selling_price        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check Null Values\n",
    "##Check features with nan value\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove Unnecessary Columns\n",
    "df.drop('car_name', axis=1, inplace=True)\n",
    "df.drop('brand', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Numerical Features : 7\n",
      "Num of Categorical Features : 4\n",
      "Num of Discrete Features : 2\n",
      "Num of Continuous Features : 5\n"
     ]
    }
   ],
   "source": [
    "## Getting All Different Types OF Features\n",
    "num_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
    "print('Num of Numerical Features :', len(num_features))\n",
    "cat_features = [feature for feature in df.columns if df[feature].dtype == 'O']\n",
    "print('Num of Categorical Features :', len(cat_features))\n",
    "discrete_features=[feature for feature in num_features if len(df[feature].unique())<=25]\n",
    "print('Num of Discrete Features :',len(discrete_features))\n",
    "continuous_features=[feature for feature in num_features if feature not in discrete_features]\n",
    "print('Num of Continuous Features :',len(continuous_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Indpendent and dependent features\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(['selling_price'], axis=1)\n",
    "y = df['selling_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Encoding and Scaling\n",
    "**One Hot Encoding for Columns which had lesser unique values and not ordinal**\n",
    "* One hot encoding is a process by which categorical variables are converted into a form that could be provided to ML algorithms to do a better job in prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['model'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model\n",
       "i20             906\n",
       "Swift Dzire     890\n",
       "Swift           781\n",
       "Alto            778\n",
       "City            757\n",
       "               ... \n",
       "Altroz            1\n",
       "C                 1\n",
       "Ghost             1\n",
       "Quattroporte      1\n",
       "Gurkha            1\n",
       "Name: count, Length: 120, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "X['model']=le.fit_transform(X['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['seller_type'].unique()),len(df['fuel_type'].unique()),len(df['transmission_type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Column Transformer with 3 types of transformers\n",
    "num_features = X.select_dtypes(exclude=\"object\").columns\n",
    "onehot_columns = ['seller_type','fuel_type','transmission_type']\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "oh_transformer = OneHotEncoder(drop='first')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\", oh_transformer, onehot_columns),\n",
    "        (\"StandardScaler\", numeric_transformer, num_features)\n",
    "        \n",
    "    ],remainder='passthrough'\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12328, 14), (3083, 14))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training And Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge,Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create a Function to Evaluate Model\n",
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
    "    r2_square = r2_score(true, predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 553855.6665\n",
      "- Mean Absolute Error: 268101.6071\n",
      "- R2 Score: 0.6218\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 502543.5930\n",
      "- Mean Absolute Error: 279618.5794\n",
      "- R2 Score: 0.6645\n",
      "===================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 553855.6710\n",
      "- Mean Absolute Error: 268099.2226\n",
      "- R2 Score: 0.6218\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 502542.6696\n",
      "- Mean Absolute Error: 279614.7461\n",
      "- R2 Score: 0.6645\n",
      "===================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 553856.3160\n",
      "- Mean Absolute Error: 268059.8015\n",
      "- R2 Score: 0.6218\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 502533.8230\n",
      "- Mean Absolute Error: 279557.2169\n",
      "- R2 Score: 0.6645\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 325873.0088\n",
      "- Mean Absolute Error: 91425.4705\n",
      "- R2 Score: 0.8691\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 253024.3951\n",
      "- Mean Absolute Error: 112526.3461\n",
      "- R2 Score: 0.9150\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 20797.2352\n",
      "- Mean Absolute Error: 5164.8199\n",
      "- R2 Score: 0.9995\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 304287.6748\n",
      "- Mean Absolute Error: 124515.6422\n",
      "- R2 Score: 0.8770\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 131923.4418\n",
      "- Mean Absolute Error: 39784.0124\n",
      "- R2 Score: 0.9785\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 226208.3255\n",
      "- Mean Absolute Error: 101601.6627\n",
      "- R2 Score: 0.9320\n",
      "===================================\n",
      "\n",
      "\n",
      "Adaboost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 432049.0890\n",
      "- Mean Absolute Error: 319885.7809\n",
      "- R2 Score: 0.7698\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 461585.9112\n",
      "- Mean Absolute Error: 337541.5033\n",
      "- R2 Score: 0.7170\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Beginning Model Training\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"Adaboost Regressor\":AdaBoostRegressor()\n",
    "   \n",
    "}\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate Train and Test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize few parameter for Hyperparamter tuning\n",
    "knn_params = {\"n_neighbors\": [2, 3, 10, 20, 40, 50]}\n",
    "rf_params = {\"max_depth\": [5, 8, 15, None, 10],\n",
    "             \"max_features\": [5, 7, \"auto\", 8],\n",
    "             \"min_samples_split\": [2, 8, 15, 20],\n",
    "             \"n_estimators\": [100, 200, 500, 1000]}\n",
    "\n",
    "ada_params={\n",
    "    \"n_estimators\":[50,60,70,80],\n",
    "    \"loss\":['linear','square','exponential']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models list for Hyperparameter tuning\n",
    "randomcv_models = [('KNN', KNeighborsRegressor(), knn_params),\n",
    "                   (\"RF\", RandomForestRegressor(), rf_params),\n",
    "                   (\"Adaboost\",AdaBoostRegressor(),ada_params)\n",
    "                   \n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "---------------- Best Params for KNN -------------------\n",
      "{'n_neighbors': 10}\n",
      "---------------- Best Params for RF -------------------\n",
      "{'n_estimators': 100, 'min_samples_split': 2, 'max_features': 7, 'max_depth': None}\n",
      "---------------- Best Params for Adaboost -------------------\n",
      "{'n_estimators': 50, 'loss': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "##Hyperparameter Tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model_param = {}\n",
    "for name, model, params in randomcv_models:\n",
    "    random = RandomizedSearchCV(estimator=model,\n",
    "                                   param_distributions=params,\n",
    "                                   n_iter=100,\n",
    "                                   cv=3,\n",
    "                                   verbose=2,\n",
    "                                   n_jobs=-1)\n",
    "    random.fit(X_train, y_train)\n",
    "    model_param[name] = random.best_params_\n",
    "\n",
    "for model_name in model_param:\n",
    "    print(f\"---------------- Best Params for {model_name} -------------------\")\n",
    "    print(model_param[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 134038.7880\n",
      "- Mean Absolute Error: 39264.9997\n",
      "- R2 Score: 0.9778\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 213806.1654\n",
      "- Mean Absolute Error: 99123.2741\n",
      "- R2 Score: 0.9393\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 363460.7706\n",
      "- Mean Absolute Error: 103472.0474\n",
      "- R2 Score: 0.8371\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 263888.0623\n",
      "- Mean Absolute Error: 117496.2131\n",
      "- R2 Score: 0.9075\n",
      "===================================\n",
      "\n",
      "\n",
      "Adaboost\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 471107.6127\n",
      "- Mean Absolute Error: 359153.3336\n",
      "- R2 Score: 0.7263\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 507641.4571\n",
      "- Mean Absolute Error: 378376.7469\n",
      "- R2 Score: 0.6577\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Retraining the models with best parameters\n",
    "models = {\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(n_estimators=100, min_samples_split=2, max_features=7, max_depth=None, \n",
    "                                                     n_jobs=-1),\n",
    "     \"K-Neighbors Regressor\": KNeighborsRegressor(n_neighbors=10, n_jobs=-1),\n",
    "     \"Adaboost\":AdaBoostRegressor(n_estimators=50,loss='linear')\n",
    "    \n",
    "}\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
